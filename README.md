# DecisionTrees-Gini-Entropy-TitanicSurvivalPrediction

This repository focuses on Building Decision Trees (Gini, Entropy) for the Titanic Survival Prediction from Kaggle Competition

Here is the link to the Kaggle competition.Although competition requires to submit predictions, I have solely used this data to just build various models of Decision Trees and the concept of Pruning to reduce the Overfitting with Decision Tree and check out the most significant features that contributed to the survival of the Titanic Passengers

https://www.kaggle.com/c/titanic

The code used for Building Decision Trees can be found in the repository with name "DecisionTrees_TitanicSurvivalPrediction.ipynb"

![dt](https://user-images.githubusercontent.com/65406908/89076741-dacd0300-d34e-11ea-9528-ae242df2cf34.png)

The data used to train/test the model is included in this directory (train_titanic.csv, test_titanic.csv)

# Decision Tree Models

Code contains 3 versions of Decision Tree Models

Model 1: Decision Tree with Gini Index Criterion

Model 2: Decision Tree with Entropy Criterion

Model 3: Decision Tree with reduced depth (Pruning) to reduce the overfitting with Model 1 and Model 2


